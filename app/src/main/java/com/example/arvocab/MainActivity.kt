package com.example.arvocab

import android.Manifest
import android.content.Context
import android.content.pm.PackageManager
import android.graphics.ImageFormat
import android.graphics.SurfaceTexture
import android.hardware.camera2.*
import android.media.AudioFormat
import android.media.AudioRecord
import android.media.MediaRecorder
import android.media.ImageReader
import android.os.Bundle
import android.os.Handler
import android.os.HandlerThread
import android.os.SystemClock
import android.util.Log
import android.util.Size
import android.view.Surface
import android.view.TextureView
import android.view.View
import android.widget.EditText
import android.widget.ImageButton
import android.widget.TextView
import android.widget.Toast
import androidx.appcompat.app.AppCompatActivity
import androidx.cardview.widget.CardView
import androidx.core.app.ActivityCompat
import androidx.core.content.ContextCompat
import androidx.lifecycle.lifecycleScope
import androidx.recyclerview.widget.LinearLayoutManager
import androidx.recyclerview.widget.RecyclerView
import kotlinx.coroutines.Dispatchers
import kotlinx.coroutines.launch
import kotlinx.coroutines.withContext
import org.tensorflow.lite.Interpreter
import java.io.FileInputStream
import java.nio.ByteBuffer
import java.nio.ByteOrder
import java.nio.MappedByteBuffer
import java.nio.channels.FileChannel
import java.text.SimpleDateFormat
import java.util.Date
import java.util.Locale
import java.util.concurrent.Semaphore
import java.util.concurrent.TimeUnit
import java.util.concurrent.atomic.AtomicBoolean

class MainActivity : AppCompatActivity() {

    private lateinit var cameraPreview: TextureView
    private lateinit var objectLabel: TextView
    private lateinit var translationView: TextView
    private lateinit var chatResponse: TextView
    // private lateinit var boundingBox: View // AR ê¸°ëŠ¥ ì œê±°ë¡œ ì¼ë‹¨ ì‚¬ìš© ì•ˆ í•¨
    private lateinit var chatContainer: CardView

    // â”€â”€â”€ Conformer TFLite ASR â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    private var asrInterpreter: Interpreter? = null
    private var isRecording = AtomicBoolean(false)
    private var audioRecord: AudioRecord? = null
    private var audioBuffer: ShortArray? = null
    private var recordingThread: Thread? = null
    private val sampleRate = 16000
    private var isAsrAvailable = false

    // ì±„íŒ… ê´€ë ¨ UI ìš”ì†Œ
    private lateinit var messageInput: EditText
    private lateinit var sendButton: ImageButton
    private lateinit var voiceButton: ImageButton
    private lateinit var chatRecyclerView: RecyclerView
    private lateinit var chatAdapter: ChatAdapter

    // ìƒˆë¡œê³ ì¹¨ ë²„íŠ¼
    private lateinit var refreshButton: ImageButton

    // ë©”ëª¨ë¦¬ ìµœì í™”ë¥¼ ìœ„í•œ ëª¨ë¸ ê´€ë¦¬
    private var objectRecognizer: ObjectRecognizer? = null
    private lateinit var translator: TranslationHelper
    private var llm: ConversationLLM? = null
    private var isLLMLoading = AtomicBoolean(false)

    private var currentLabel: String? = null
    private val isProcessing = AtomicBoolean(false)

    // ì¸ì‹ ì¼ì‹œ ì¤‘ì§€ í”Œë˜ê·¸
    private val isPaused = AtomicBoolean(false)

    private val minProcessIntervalMs = 1000L
    private var lastProcessAt = 0L
    private val timeFormat = SimpleDateFormat("HH:mm:ss", Locale.getDefault())

    private var cameraDevice: CameraDevice? = null
    private var captureSession: CameraCaptureSession? = null
    private lateinit var previewSize: Size
    private lateinit var imageReader: ImageReader
    private lateinit var previewRequestBuilder: CaptureRequest.Builder

    private var backgroundThread: HandlerThread? = null
    private var backgroundHandler: Handler? = null
    private val cameraOpenCloseLock = Semaphore(1)

    companion object {
        private const val TAG = "MainActivity"
        private const val CAMERA_PERMISSION_REQUEST_CODE = 1001
        private const val RECORD_AUDIO_PERMISSION_REQUEST_CODE = 1002
        private const val PREVIEW_WIDTH = 640  // ì›í•˜ëŠ” í”„ë¦¬ë·° ë„ˆë¹„
        private const val PREVIEW_HEIGHT = 480 // ì›í•˜ëŠ” í”„ë¦¬ë·° ë†’ì´
    }

    /**
     * Assets í´ë”ì—ì„œ .tflite íŒŒì¼ì„ MappedByteBufferë¡œ ì½ì–´ì˜¤ëŠ” í—¬í¼
     */
    private fun loadModelFile(filename: String): MappedByteBuffer {
        val fd = assets.openFd(filename)
        FileInputStream(fd.fileDescriptor).use { input ->
            return input.channel.map(
                FileChannel.MapMode.READ_ONLY,
                fd.startOffset,
                fd.declaredLength
            )
        }
    }

    override fun onCreate(savedInstanceState: Bundle?) {
        super.onCreate(savedInstanceState)
        setContentView(R.layout.activity_main)

        // â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 1) Conformer TFLite Interpreter ì´ˆê¸°í™” â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        try {
            asrInterpreter = Interpreter(loadModelFile("conformer_librispeech.tflite"),
                Interpreter.Options().apply {
                    setNumThreads(4)
                    // GPU Delegate ì‚¬ìš© ì‹œ ì•„ë˜ ì£¼ì„ í•´ì œ í›„ import
                    // addDelegate(GpuDelegate())
                })
            isAsrAvailable = true
            Log.i(TAG, "ASR model initialized successfully")
        } catch (e: Exception) {
            Log.w(TAG, "ASR model not available: ${e.message}")
            isAsrAvailable = false
            // ASR ì—†ì´ë„ ì•±ì€ ì •ìƒ ì‘ë™
        }

        // â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 2) UI ë°”ì¸ë”© â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        cameraPreview = findViewById(R.id.cameraPreview)
        objectLabel = findViewById(R.id.objectLabel)
        translationView = findViewById(R.id.translationView)
        chatResponse = findViewById(R.id.chatResponse)
        // boundingBox = findViewById(R.id.boundingBox) // AR ê¸°ëŠ¥ ì œê±°
        chatContainer = findViewById(R.id.chatContainer)

        messageInput = findViewById(R.id.messageInput)
        sendButton = findViewById(R.id.sendButton)
        voiceButton = findViewById(R.id.voiceButton)
        chatRecyclerView = findViewById(R.id.chatRecyclerView)
        refreshButton = findViewById(R.id.refreshButton)

        chatAdapter = ChatAdapter()
        chatRecyclerView.layoutManager = LinearLayoutManager(this)
        chatRecyclerView.adapter = chatAdapter

        // ë©”ëª¨ë¦¬ ìµœì í™”: ObjectRecognizerë§Œ ë¨¼ì € ì´ˆê¸°í™”
        objectRecognizer = ObjectRecognizer(this)
        translator = TranslationHelper(this, "en", "ko")
        // ConversationLLMì€ ì§€ì—° ë¡œë”©ìœ¼ë¡œ ë³€ê²½
        Log.i(TAG, "ConversationLLM will be loaded after object recognition")

        // â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 3) sendButton í´ë¦­ ë¦¬ìŠ¤ë„ˆ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        sendButton.setOnClickListener {
            val message = messageInput.text.toString().trim()
            if (message.isNotEmpty()) {
                sendMessage(message)
                messageInput.text.clear()
            }
        }

        // â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 4) voiceButton(ë§ˆì´í¬) í´ë¦­ ë¦¬ìŠ¤ë„ˆ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        // ì˜ˆ: ë§ˆì´í¬ ë²„íŠ¼ í´ë¦­ ë¦¬ìŠ¤ë„ˆ ë‚´ë¶€
        voiceButton.setOnClickListener {
            if (ContextCompat.checkSelfPermission(this, Manifest.permission.RECORD_AUDIO)
                != PackageManager.PERMISSION_GRANTED
            ) {
                ActivityCompat.requestPermissions(
                    this,
                    arrayOf(Manifest.permission.RECORD_AUDIO),
                    RECORD_AUDIO_PERMISSION_REQUEST_CODE
                )
            } else {
                toggleRecording()
            }
        }


        // â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 5) ìƒˆë¡œê³ ì¹¨ ë²„íŠ¼ í´ë¦­ ë¦¬ìŠ¤ë„ˆ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        refreshButton.setOnClickListener {
            // ë©”ëª¨ë¦¬ ìµœì í™”ë¥¼ ìœ„í•´ ObjectRecognizer ì¬ì´ˆê¸°í™”
            releaseObjectRecognizer()
            objectRecognizer = ObjectRecognizer(this)
            
            isPaused.set(false)
            currentLabel = null
            objectLabel.text = ""
            translationView.text = ""
            chatResponse.text = ""

            chatAdapter.addMessage("ì¸ì‹ì´ ì¬ê°œë˜ì—ˆìŠµë‹ˆë‹¤. ìƒˆë¡œìš´ ë¬¼ì²´ë¥¼ ì¸ì‹í•´ë³´ì„¸ìš”.", false)
            chatRecyclerView.scrollToPosition(chatAdapter.itemCount - 1)

            Toast.makeText(this, "ì¸ì‹ì´ ì¬ê°œë˜ì—ˆìŠµë‹ˆë‹¤", Toast.LENGTH_SHORT).show()
        }
    }

    private val surfaceTextureListener = object : TextureView.SurfaceTextureListener {
        override fun onSurfaceTextureAvailable(surface: SurfaceTexture, width: Int, height: Int) {
            openCamera(width, height)
        }
        override fun onSurfaceTextureSizeChanged(surface: SurfaceTexture, width: Int, height: Int) {}
        override fun onSurfaceTextureDestroyed(surface: SurfaceTexture): Boolean = true
        override fun onSurfaceTextureUpdated(surface: SurfaceTexture) {}
    }

    private val imageAvailableListener = ImageReader.OnImageAvailableListener { reader ->
        val image = reader.acquireLatestImage() ?: return@OnImageAvailableListener

        if (isPaused.get() || objectRecognizer == null) {
            image.close()
            return@OnImageAvailableListener
        }

        val now = SystemClock.uptimeMillis()
        if (now - lastProcessAt < minProcessIntervalMs || !isProcessing.compareAndSet(false, true)) {
            image.close()
            return@OnImageAvailableListener
        }
        lastProcessAt = now

        lifecycleScope.launch(Dispatchers.Default) {
            try {
                val bitmap = objectRecognizer?.yuvToBitmap(image)
                image.close()

                if (bitmap == null) {
                    Log.w(TAG, "ObjectRecognizer is null, skipping recognition")
                    return@launch
                }

                val (recognizedLabel, score) = objectRecognizer!!.recognize(bitmap)
                bitmap.recycle()

                if (recognizedLabel.isNotBlank() && recognizedLabel != currentLabel && score > 0.1) {
                    currentLabel = recognizedLabel
                    isPaused.set(true)

                    // ë©”ëª¨ë¦¬ ìµœì í™”: ê°ì²´ ì¸ì‹ ì„±ê³µ í›„ ObjectRecognizer í•´ì œí•˜ê³  LLM ë¡œë“œ
                    releaseObjectRecognizer()
                    loadLLMIfNeeded()

                    launch(Dispatchers.Main) {
                        val currentTime = timeFormat.format(Date())

                        objectLabel.text = "[$currentTime]It is $recognizedLabel."
                        translationView.text = ""
                        chatResponse.text = ""
                        chatContainer.visibility = if (recognizedLabel != "Unknown") View.VISIBLE else View.GONE
                        refreshButton.visibility = View.VISIBLE

                        if (recognizedLabel != "Unknown") {
                            lifecycleScope.launch(Dispatchers.IO) {
                                try {
                                    val translated = translator.translate(recognizedLabel)
                                    launch(Dispatchers.Main) {
                                        translationView.text = translated
                                        chatAdapter.addMessage("ì¸ì‹ëœ ë¬¼ì²´: $recognizedLabel", false)
                                        chatAdapter.addMessage("í•œêµ­ì–´ ë²ˆì—­: $translated", false)
                                        val infoMessage = "ì´ ë¬¼ì²´ì— ëŒ€í•´ ë” ì•Œê³  ì‹¶ì€ ê²ƒì´ ìˆìœ¼ë©´ ì§ˆë¬¸í•´ì£¼ì„¸ìš”."
                                        chatAdapter.addMessage(infoMessage, false)
                                        chatRecyclerView.scrollToPosition(chatAdapter.itemCount - 1)
                                    }
                                } catch (e: Exception) {
                                    Log.e(TAG, "Translation error: ${e.message}", e)
                                }
                            }
                        }
                    }
                }
            } catch (e: Exception) {
                Log.e(TAG, "Error during recognition: ${e.message}", e)
            } finally {
                isProcessing.set(false)
            }
        }
    }

    private val cameraStateCallback = object : CameraDevice.StateCallback() {
        override fun onOpened(camera: CameraDevice) {
            cameraOpenCloseLock.release()
            cameraDevice = camera
            createCameraPreviewSession()
        }

        override fun onDisconnected(camera: CameraDevice) {
            cameraOpenCloseLock.release()
            camera.close()
            cameraDevice = null
        }

        override fun onError(camera: CameraDevice, error: Int) {
            cameraOpenCloseLock.release()
            camera.close()
            cameraDevice = null
            Log.e(TAG, "CameraDevice Error: $error")
            finish()
        }
    }

    override fun onResume() {
        super.onResume()
        startBackgroundThread()
        if (cameraPreview.isAvailable) {
            openCamera(cameraPreview.width, cameraPreview.height)
        } else {
            cameraPreview.surfaceTextureListener = surfaceTextureListener
        }
    }

    override fun onPause() {
        closeCamera()
        stopBackgroundThread()
        super.onPause()
    }

    private fun startBackgroundThread() {
        backgroundThread = HandlerThread("CameraBackground").also { it.start() }
        backgroundHandler = Handler(backgroundThread!!.looper)
    }

    private fun stopBackgroundThread() {
        backgroundThread?.quitSafely()
        try {
            backgroundThread?.join()
            backgroundThread = null
            backgroundHandler = null
        } catch (e: InterruptedException) {
            Log.e(TAG, "Error stopping background thread", e)
        }
    }

    private fun checkCameraPermission(): Boolean =
        ContextCompat.checkSelfPermission(this, Manifest.permission.CAMERA) == PackageManager.PERMISSION_GRANTED

    private fun requestCameraPermission() {
        ActivityCompat.requestPermissions(this, arrayOf(Manifest.permission.CAMERA), CAMERA_PERMISSION_REQUEST_CODE)
    }

    private fun openCamera(width: Int, height: Int) {
        if (!checkCameraPermission()) {
            requestCameraPermission()
            return
        }
        val cameraManager = getSystemService(Context.CAMERA_SERVICE) as CameraManager
        try {
            val cameraId = cameraManager.cameraIdList.firstOrNull {
                cameraManager.getCameraCharacteristics(it)
                    .get(CameraCharacteristics.LENS_FACING) == CameraCharacteristics.LENS_FACING_BACK
            } ?: throw IllegalStateException("No back-facing camera found")

            val characteristics = cameraManager.getCameraCharacteristics(cameraId)
            val map = characteristics.get(CameraCharacteristics.SCALER_STREAM_CONFIGURATION_MAP)!!

            previewSize = map.getOutputSizes(ImageFormat.YUV_420_888)
                .firstOrNull { it.width == PREVIEW_WIDTH && it.height == PREVIEW_HEIGHT }
                ?: map.getOutputSizes(ImageFormat.YUV_420_888).maxByOrNull { it.width * it.height }!!

            imageReader = ImageReader.newInstance(previewSize.width, previewSize.height, ImageFormat.YUV_420_888, 5)
            imageReader.setOnImageAvailableListener(imageAvailableListener, backgroundHandler)

            if (!cameraOpenCloseLock.tryAcquire(2500, TimeUnit.MILLISECONDS)) {
                throw RuntimeException("Time out waiting to lock camera opening.")
            }
            cameraManager.openCamera(cameraId, cameraStateCallback, backgroundHandler)

        } catch (e: CameraAccessException) {
            Log.e(TAG, "Cannot access the camera.", e)
        } catch (e: InterruptedException) {
            throw RuntimeException("Interrupted while trying to lock camera opening.", e)
        }
    }

    private fun closeCamera() {
        try {
            cameraOpenCloseLock.acquire()
            captureSession?.close()
            captureSession = null
            cameraDevice?.close()
            cameraDevice = null
            imageReader.close()
        } catch (e: InterruptedException) {
            throw RuntimeException("Interrupted while trying to lock camera closing.", e)
        } finally {
            cameraOpenCloseLock.release()
        }
    }

    private fun createCameraPreviewSession() {
        try {
            val texture = cameraPreview.surfaceTexture!!
            texture.setDefaultBufferSize(previewSize.width, previewSize.height)
            val surface = Surface(texture)

            previewRequestBuilder = cameraDevice!!.createCaptureRequest(CameraDevice.TEMPLATE_PREVIEW)
            previewRequestBuilder.addTarget(surface)
            previewRequestBuilder.addTarget(imageReader.surface)

            cameraDevice?.createCaptureSession(
                listOf(surface, imageReader.surface),
                object : CameraCaptureSession.StateCallback() {
                    override fun onConfigured(session: CameraCaptureSession) {
                        if (cameraDevice == null) return
                        captureSession = session
                        try {
                            previewRequestBuilder.set(
                                CaptureRequest.CONTROL_AF_MODE,
                                CaptureRequest.CONTROL_AF_MODE_CONTINUOUS_PICTURE
                            )
                            previewRequestBuilder.set(
                                CaptureRequest.CONTROL_AE_MODE,
                                CaptureRequest.CONTROL_AE_MODE_ON_AUTO_FLASH
                            )
                            captureSession?.setRepeatingRequest(previewRequestBuilder.build(), null, backgroundHandler)
                        } catch (e: CameraAccessException) {
                            Log.e(TAG, "Failed to start camera preview", e)
                        }
                    }

                    override fun onConfigureFailed(session: CameraCaptureSession) {
                        Toast.makeText(this@MainActivity, "Failed to configure camera.", Toast.LENGTH_SHORT).show()
                    }
                },
                null
            )
        } catch (e: CameraAccessException) {
            Log.e(TAG, "Error creating camera preview session", e)
        }
    }

    override fun onRequestPermissionsResult(
        requestCode: Int,
        permissions: Array<out String>,
        grantResults: IntArray
    ) {
        super.onRequestPermissionsResult(requestCode, permissions, grantResults)
        if (requestCode == RECORD_AUDIO_PERMISSION_REQUEST_CODE) {
            if (grantResults.isNotEmpty() && grantResults[0] == PackageManager.PERMISSION_GRANTED) {
                toggleRecording()
            } else {
                Toast.makeText(this, "ë§ˆì´í¬ ê¶Œí•œì´ í•„ìš”í•©ë‹ˆë‹¤.", Toast.LENGTH_SHORT).show()
            }
        }
        // CAMERA ê¶Œí•œ ì²˜ë¦¬ë„ ë§ˆì°¬ê°€ì§€
        if (requestCode == CAMERA_PERMISSION_REQUEST_CODE) {
            if (grantResults.isNotEmpty() && grantResults[0] == PackageManager.PERMISSION_GRANTED) {
                openCamera(cameraPreview.width, cameraPreview.height)
            } else {
                Toast.makeText(this, "ì¹´ë©”ë¼ ê¶Œí•œì´ í•„ìš”í•©ë‹ˆë‹¤.", Toast.LENGTH_LONG).show()
            }
        }
    }


    // â”€â”€â”€ ë…¹ìŒ í† ê¸€ í•¨ìˆ˜ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    private fun toggleRecording() {
        if (isRecording.get()) {
            stopRecording()
        } else {
            startRecording()
        }
    }

    // â”€â”€â”€ AudioRecord ì´ˆê¸°í™” â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    private fun initAudioRecorder() {
        if (ContextCompat.checkSelfPermission(this, Manifest.permission.RECORD_AUDIO)
            != PackageManager.PERMISSION_GRANTED) {
            throw SecurityException("RECORD_AUDIO permission not granted")
        }
        
        val minBufferSize = AudioRecord.getMinBufferSize(
            sampleRate,
            AudioFormat.CHANNEL_IN_MONO,
            AudioFormat.ENCODING_PCM_16BIT
        )
        audioBuffer = ShortArray(minBufferSize)
        audioRecord = AudioRecord(
            MediaRecorder.AudioSource.MIC,
            sampleRate,
            AudioFormat.CHANNEL_IN_MONO,
            AudioFormat.ENCODING_PCM_16BIT,
            minBufferSize
        )
    }

    // â”€â”€â”€ ë…¹ìŒ ì‹œì‘ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    private fun startRecording() {
        try {
            initAudioRecorder()
            audioRecord?.startRecording()
            isRecording.set(true)
            voiceButton.setImageResource(R.drawable.ic_mic)

            val thread = Thread {
                val pcmList = mutableListOf<Short>()
                val buffer = audioBuffer
                val recorder = audioRecord
                
                while (isRecording.get() && buffer != null && recorder != null) {
                    val read = recorder.read(buffer, 0, buffer.size)
                    if (read > 0) {
                        for (i in 0 until read) {
                            pcmList.add(buffer[i])
                        }
                    }
                }
                val pcmData = pcmList.toShortArray()
                runConformerInferenceRaw(pcmData)
            }
            recordingThread = thread
            thread.start()
        } catch (e: SecurityException) {
            Log.e(TAG, "RECORD_AUDIO permission not granted", e)
            Toast.makeText(this, "ë§ˆì´í¬ ê¶Œí•œì´ í•„ìš”í•©ë‹ˆë‹¤.", Toast.LENGTH_SHORT).show()
        }
    }

    // â”€â”€â”€ ë…¹ìŒ ì¤‘ì§€ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    private fun stopRecording() {
        isRecording.set(false)
        audioRecord?.stop()
        audioRecord?.release()
        voiceButton.setImageResource(R.drawable.ic_mic)
    }

    // â”€â”€â”€ Conformer TFLite ì¶”ë¡  (Raw PCM ê¸°ë°˜ ASR) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    private fun runConformerInferenceRaw(pcmData: ShortArray) {
        lifecycleScope.launch(Dispatchers.IO) {
            try {
                // 1) PCM(short[]) â†’ FloatArray ì •ê·œí™”
                val floatPCM = FloatArray(pcmData.size) { i ->
                    pcmData[i].toFloat() / Short.MAX_VALUE
                }

                // 2) ì…ë ¥ í…ì„œ í¬ê¸° ì¬ì¡°ì • ë° allocateTensors()
                asrInterpreter?.resizeInput(0, intArrayOf(floatPCM.size))
                asrInterpreter?.allocateTensors()

                // 3) ì…ë ¥ í…ì„œ ì¤€ë¹„
                // 3-1) raw PCM float ë°ì´í„°
                val buf0 = ByteBuffer.allocateDirect(4 * floatPCM.size)
                    .order(ByteOrder.nativeOrder())
                for (f in floatPCM) buf0.putFloat(f)
                buf0.rewind()

                // 3-2) int32 scalar 0
                val buf1 = ByteBuffer.allocateDirect(4).order(ByteOrder.nativeOrder())
                buf1.putInt(0).rewind()

                // 3-3) zeros([1,2,1,320], float32)
                val zeroCount = 1 * 2 * 1 * 320
                val buf2 = ByteBuffer.allocateDirect(4 * zeroCount)
                    .order(ByteOrder.nativeOrder())
                repeat(zeroCount) { buf2.putFloat(0f) }
                buf2.rewind()

                // 4) ì…ë ¥ ë°°ì—´ êµ¬ì„±
                val inputs = arrayOf(buf0, buf1, buf2)

                // 5) ì¶œë ¥ í…ì„œ ì¤€ë¹„
                val outputTensor = asrInterpreter?.getOutputTensor(0)
                val outShape = outputTensor?.shape()
                val outCount = outShape?.reduce { a, b -> a * b } ?: 0
                val outputBuffer = ByteBuffer.allocateDirect(4 * outCount)
                    .order(ByteOrder.nativeOrder())
                val outputs = mapOf(0 to outputBuffer)

                // 6) ì¶”ë¡  ì‹¤í–‰
                asrInterpreter?.runForMultipleInputsOutputs(inputs, outputs)

                // 7) ì¶œë ¥ ì²˜ë¦¬
                outputBuffer.rewind()
                val tokenInts = IntArray(outCount)
                for (i in 0 until outCount) {
                    tokenInts[i] = outputBuffer.int
                }

                // 5-1) Greedy CTC ë””ì½”ë”© (ì—°ì† ì¤‘ë³µ ì œê±° & blank(0) ì œê±°)
                val sb = StringBuilder()
                var prev = -1
                for (u in tokenInts) {
                    if (u != prev && u != 0) {
                        sb.append(Char(u))
                    }
                    prev = u
                }
                val recognizedText = sb.toString()

                // 6) UI ì—…ë°ì´íŠ¸ ë° ê¸°ì¡´ sendMessage() í˜¸ì¶œ
                withContext(Dispatchers.Main) {
                    if (recognizedText.isNotBlank()) {
                        messageInput.setText(recognizedText)
                        sendMessage(recognizedText)
                    } else {
                        Toast.makeText(this@MainActivity, "ìŒì„± ì¸ì‹ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.", Toast.LENGTH_SHORT).show()
                    }
                }

            } catch (e: Exception) {
                Log.e(TAG, "Conformer ASR ì˜¤ë¥˜: ${e.message}", e)
                withContext(Dispatchers.Main) {
                    Toast.makeText(this@MainActivity, "ìŒì„± ì¸ì‹ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.", Toast.LENGTH_SHORT).show()
                }
            }
        }
    }

    // â”€â”€â”€ CLIP ê¸°ë°˜ ê°ì²´ ì¸ì‹ & ì¹´ë©”ë¼ ì„¤ì • (ê¸°ì¡´ ì½”ë“œ ê·¸ëŒ€ë¡œ) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    // surfaceTextureListener, imageAvailableListener, openCamera(), createCameraPreviewSession(), closeCamera(), etc.

    // â”€â”€â”€ ì±„íŒ… ë©”ì‹œì§€ ì „ì†¡ ë° LLM ì‘ë‹µ ì²˜ë¦¬ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    private fun sendMessage(message: String) {
        chatAdapter.addMessage(message, true)
        chatRecyclerView.scrollToPosition(chatAdapter.itemCount - 1)

        val original = currentLabel ?: ""
        lifecycleScope.launch(Dispatchers.IO) {
            try {
                val translated = if (original.isNotEmpty() && original != "Unknown") {
                    translator.translate(original)
                } else {
                    ""
                }
                
                // LLMì´ ë¡œë“œë  ë•Œê¹Œì§€ ëŒ€ê¸°
                var attempts = 0
                while (llm == null && attempts < 100) { // ìµœëŒ€ 10ì´ˆ ëŒ€ê¸°
                    kotlinx.coroutines.delay(100)
                    attempts++
                    
                    // ì§„í–‰ ìƒí™© ì—…ë°ì´íŠ¸
                    if (attempts % 20 == 0) { // 2ì´ˆë§ˆë‹¤
                        withContext(Dispatchers.Main) {
                            chatAdapter.addMessage("â³ AI ëª¨ë¸ ë¡œë”© ì¤‘... (${attempts/10}ì´ˆ ê²½ê³¼)", false)
                            chatRecyclerView.scrollToPosition(chatAdapter.itemCount - 1)
                        }
                    }
                }
                
                val response = if (llm != null) {
                    // ì‹¤ì œ ëª¨ë¸ ì‚¬ìš© ìƒíƒœ í™•ì¸
                    val isUsingRealModel = llm!!.isReady()
                    Log.i(TAG, "Using real T5 model: $isUsingRealModel")
                    
                    llm!!.chat(original, translated, message)
                } else {
                    "ì£„ì†¡í•©ë‹ˆë‹¤. T5 AI ëª¨ë¸ì´ ì•„ì§ ë¡œë“œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”."
                }
                
                withContext(Dispatchers.Main) {
                    chatAdapter.addMessage(response, false)
                    chatRecyclerView.scrollToPosition(chatAdapter.itemCount - 1)
                    
                    // ì‹¤ì œ ëª¨ë¸ ì‚¬ìš© ì—¬ë¶€ í‘œì‹œ
                    val modelStatus = llm?.let { 
                        if (it.isReady()) "ğŸŸ¢ ì‹¤ì œ T5 ëª¨ë¸ ì‚¬ìš©" else "ğŸŸ¡ ìŠ¤ë§ˆíŠ¸ í´ë°± ëª¨ë“œ"
                    } ?: "ğŸ”´ ëª¨ë¸ ë¯¸ë¡œë“œ"
                    
                    Log.i(TAG, "Model status: $modelStatus")
                }
            } catch (e: Exception) {
                Log.e(TAG, "sendMessage ì—ëŸ¬: ${e.message}", e)
                withContext(Dispatchers.Main) {
                    chatAdapter.addMessage("Sorry, I couldn't process your message: ${e.message}", false)
                    chatRecyclerView.scrollToPosition(chatAdapter.itemCount - 1)
                }
            }
        }
    }

    // ObjectRecognizer ë©”ëª¨ë¦¬ í•´ì œ
    private fun releaseObjectRecognizer() {
        objectRecognizer = null
        System.gc() // ê°€ë¹„ì§€ ì»¬ë ‰ì…˜ ê°•ì œ ì‹¤í–‰
        Log.i(TAG, "ObjectRecognizer released for memory optimization")
    }

    // ConversationLLM ì§€ì—° ë¡œë”©
    private fun loadLLMIfNeeded() {
        if (llm == null && !isLLMLoading.get()) {
            isLLMLoading.set(true)
            
            // ë¡œë”© ì‹œì‘ ì•Œë¦¼
            lifecycleScope.launch(Dispatchers.Main) {
                chatAdapter.addMessage("ğŸ¤– Loagind model...", false)
                chatRecyclerView.scrollToPosition(chatAdapter.itemCount - 1)
            }
            
            lifecycleScope.launch(Dispatchers.IO) {
                try {
                    Log.i(TAG, "Loading ConversationLLM after object recognition...")
                    llm = ConversationLLM(this@MainActivity)
                    
                    // ë¡œë”© ì™„ë£Œ í›„ ìƒíƒœ í™•ì¸
                    kotlinx.coroutines.delay(1000) // ì´ˆê¸°í™” ì‹œê°„ ì—¬ìœ 
                    
                    withContext(Dispatchers.Main) {
                        val status = llm?.getDetailedStatus() ?: "âŒ ë¡œë”© ì‹¤íŒ¨"
                        val isRealModel = llm?.isReady() ?: false
                        
                        if (isRealModel) {
                            chatAdapter.addMessage("âœ… Model is successfully loaded!", false)
                        } else {
                            chatAdapter.addMessage("âš ï¸ T5 ëª¨ë¸ ë¡œë”©ì— ì‹¤íŒ¨í–ˆì§€ë§Œ, ìŠ¤ë§ˆíŠ¸ í´ë°± ëª¨ë“œë¡œ ì‘ë™í•©ë‹ˆë‹¤.\n$status", false)
                        }
                        chatRecyclerView.scrollToPosition(chatAdapter.itemCount - 1)
                    }
                    
                    Log.i(TAG, "ConversationLLM loaded successfully")
                } catch (e: Exception) {
                    Log.e(TAG, "Failed to load ConversationLLM: ${e.message}", e)
                    withContext(Dispatchers.Main) {
                        chatAdapter.addMessage("âŒ T5 ëª¨ë¸ ë¡œë”©ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤: ${e.message}", false)
                        chatRecyclerView.scrollToPosition(chatAdapter.itemCount - 1)
                    }
                } finally {
                    isLLMLoading.set(false)
                }
            }
        }
    }

    override fun onDestroy() {
        super.onDestroy()
        // ë©”ëª¨ë¦¬ ì •ë¦¬
        releaseObjectRecognizer()
        llm = null
        asrInterpreter?.close()
    }
}
